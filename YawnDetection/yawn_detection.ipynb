{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "positive-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "southwest-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For detecting faces\n",
    "detector = dlib.get_frontal_face_detector() \n",
    "landmark_path=\"shape_predictor_68_face_landmarks.dat\" \n",
    "#For identifying landmarks\n",
    "predictor = dlib.shape_predictor(landmark_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "systematic-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining Facial Landmark coordinates\n",
    "def get_facial_landmarks(image):\n",
    "    face = detector(image, 1)\n",
    "    #Detecting faces in image\n",
    "    if len(face) > 1:\n",
    "        return \"Multiple faces detected in the frame!!\"\n",
    "    if len(face) == 0:\n",
    "        return \"No face detected in the frame!!\"\n",
    "    #Return the coordinates\n",
    "    return np.matrix([[pred.x, pred.y] for pred in predictor(image, face[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greater-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing the landmarks : yellow in color \n",
    "def landmarks_annotation(image, facial_landmarks):\n",
    "    \n",
    "    image = image.copy()\n",
    "    for coord, p in enumerate(facial_landmarks):\n",
    "        position = (p[0, 0], p[0, 1])\n",
    "        cv2.putText(image, str(coord), position, cv2.FONT_HERSHEY_COMPLEX, 0.3, (0, 255, 255))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exotic-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Landmark coordinates for upper lip identified in the face \n",
    "def upperlip(facial_landmarks):\n",
    "    ulip = []\n",
    "    #create an array to store the landmark coordinates of the upper lip\n",
    "    for i in range(50,53):\n",
    "        ulip.append(facial_landmarks[i])\n",
    "    for i in range(61,64):\n",
    "        ulip.append(facial_landmarks[i])\n",
    "    \n",
    "    ulip_mean = np.mean(ulip, axis=0)\n",
    "    return int(ulip_mean[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portable-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Landmark coordinates for lower lip identified in the face \n",
    "def lowerlip(facial_landmarks):\n",
    "    llip = []\n",
    "    #create an array to store the landmark coordinates of the lower lip\n",
    "    for i in range(65,68):\n",
    "        llip.append(facial_landmarks[i])\n",
    "    for i in range(56,59):\n",
    "        llip.append(facial_landmarks[i])\n",
    "        \n",
    "    llip_mean = np.mean(llip, axis=0)\n",
    "    return int(llip_mean[:,1])#centroid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the yawning activity\n",
    "def yawning(image):\n",
    "    #Obtain the facial Landmark coordinates\n",
    "    facial_landmarks = get_facial_landmarks(image)\n",
    "    if type(facial_landmarks) == str:\n",
    "        return image, 0\n",
    "    \n",
    "    #Obtain the frame / image with annotated facial landmarks\n",
    "    landmarks_image = landmarks_annotation(image, facial_landmarks)\n",
    "    \n",
    "    #Obtain Lip centroids\n",
    "    upperlip_centroid = upperlip(facial_landmarks)\n",
    "    lower_lip_centroid = lowerlip(facial_landmarks)\n",
    "    \n",
    "    #Calculate the distance between the centroids\n",
    "    lips_dist = abs(upperlip_centroid - lower_lip_centroid)\n",
    "    return landmarks_image, lips_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premier-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "yawn_status = False \n",
    "yawn_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "serial-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('dumb.jpg')\n",
    "landmarks_image, lips_dist = yawning(img)\n",
    "\n",
    "#Update the yawn status\n",
    "previous_status = yawn_status  \n",
    "\n",
    "#lips distance is subjective and changes from subject to subject based on their facial structures\n",
    "if lips_dist > 47:\n",
    "    \n",
    "    yawn_status = True\n",
    "    cv2.putText(img, \"You are yawning\", (50,450), cv2.FONT_HERSHEY_COMPLEX, 1,(0,255,255))\n",
    "        \n",
    "else:\n",
    "    yawn_status = False \n",
    "    cv2.putText(img, \"You are not yawning\", (50,450), cv2.FONT_HERSHEY_COMPLEX, 1,(255,0,0))\n",
    "        \n",
    "\n",
    "cv2.imshow('Yawning Activity Detection', img )\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-diameter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
